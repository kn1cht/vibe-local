#!/bin/bash
# claude-local.sh
# ãƒ­ãƒ¼ã‚«ãƒ«LLM (Ollama) ã§ Claude Code ã‚’èµ·å‹•ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# Anthropic API â†’ Ollama å¤‰æ›ãƒ—ãƒ­ã‚­ã‚·ã‚’è‡ªå‹•ç®¡ç†
#
# ä½¿ã„æ–¹:
#   claude-local                    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
#   claude-local -p "è³ªå•"          # ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
#   claude-local --auto             # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çŠ¶æ³ã§è‡ªå‹•åˆ¤å®š
#   claude-local --model qwen3:8b   # ãƒ¢ãƒ‡ãƒ«æ‰‹å‹•æŒ‡å®š

set -euo pipefail

# --- è¨­å®šèª­ã¿è¾¼ã¿ ---
CONFIG_FILE="${HOME}/.config/claude-local/config"
PROXY_LIB_DIR="${HOME}/.local/lib/claude-local"
PROXY_SCRIPT="${PROXY_LIB_DIR}/anthropic-ollama-proxy.py"

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
MODEL=""
OLLAMA_HOST="http://localhost:11434"
PROXY_PORT=8082

# config ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
if [ -f "$CONFIG_FILE" ]; then
    # shellcheck source=/dev/null
    source "$CONFIG_FILE"
fi

# config ãŒç„¡ã„å ´åˆã€RAM ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•åˆ¤å®š
if [ -z "$MODEL" ]; then
    if [[ "$(uname)" == "Darwin" ]]; then
        RAM_GB=$(( $(sysctl -n hw.memsize) / 1073741824 ))
    else
        RAM_GB=$(( $(grep MemTotal /proc/meminfo | awk '{print $2}') / 1048576 ))
    fi

    if [ "$RAM_GB" -ge 32 ]; then
        MODEL="qwen3-coder:30b"
    elif [ "$RAM_GB" -ge 16 ]; then
        MODEL="qwen3:8b"
    elif [ "$RAM_GB" -ge 8 ]; then
        MODEL="qwen3:1.7b"
    else
        echo "ã‚¨ãƒ©ãƒ¼: ãƒ¡ãƒ¢ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™ (${RAM_GB}GB)ã€‚æœ€ä½8GBå¿…è¦ã§ã™ã€‚"
        exit 1
    fi
fi

PROXY_URL="http://127.0.0.1:${PROXY_PORT}"
PROXY_PID_FILE="/tmp/anthropic-ollama-proxy.pid"

# --- é–‹ç™ºæ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ—ãƒ­ã‚­ã‚·ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ¢ç´¢ ---
if [ ! -f "$PROXY_SCRIPT" ]; then
    # install.sh å®Ÿè¡Œå‰ã§ã‚‚å‹•ãã‚ˆã†ã«ã€åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¢ã™
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    if [ -f "${SCRIPT_DIR}/anthropic-ollama-proxy.py" ]; then
        PROXY_SCRIPT="${SCRIPT_DIR}/anthropic-ollama-proxy.py"
    else
        echo "ã‚¨ãƒ©ãƒ¼: ãƒ—ãƒ­ã‚­ã‚·ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        echo "  install.sh ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€anthropic-ollama-proxy.py ã‚’åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç½®ã„ã¦ãã ã•ã„"
        exit 1
    fi
fi

# --- ollama ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªãƒ»èµ·å‹• ---
ensure_ollama() {
    if curl -s --max-time 2 "$OLLAMA_HOST/api/tags" &>/dev/null; then
        return 0
    fi

    echo "ğŸ¦™ ollama ã‚’èµ·å‹•ä¸­..."
    if [[ "$(uname)" == "Darwin" ]]; then
        open -a Ollama 2>/dev/null || ollama serve &>/dev/null &
    else
        ollama serve &>/dev/null &
    fi

    for i in $(seq 1 15); do
        sleep 2
        if curl -s --max-time 2 "$OLLAMA_HOST/api/tags" &>/dev/null; then
            echo "âœ… ollama èµ·å‹•å®Œäº†"
            return 0
        fi
    done

    echo "âŒ ã‚¨ãƒ©ãƒ¼: ollama ãŒèµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    echo ""
    echo "å¯¾å‡¦æ³•:"
    echo "  macOS: Ollama ã‚¢ãƒ—ãƒªã‚’æ‰‹å‹•ã§èµ·å‹•ã—ã¦ãã ã•ã„"
    echo "  Linux: ollama serve ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„"
    return 1
}

# --- å¤‰æ›ãƒ—ãƒ­ã‚­ã‚·ã®èµ·å‹• ---
ensure_proxy() {
    if curl -s --max-time 1 "$PROXY_URL/" &>/dev/null; then
        return 0
    fi

    # å¤ã„PIDãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°æƒé™¤
    if [ -f "$PROXY_PID_FILE" ]; then
        kill "$(cat "$PROXY_PID_FILE")" 2>/dev/null || true
        rm -f "$PROXY_PID_FILE"
    fi

    echo "ğŸ”„ Anthropicâ†’Ollama å¤‰æ›ãƒ—ãƒ­ã‚­ã‚·ã‚’èµ·å‹•ä¸­..."
    python3 "$PROXY_SCRIPT" "$PROXY_PORT" &>/tmp/claude-local-proxy.log &
    local pid=$!
    echo "$pid" > "$PROXY_PID_FILE"

    for i in $(seq 1 10); do
        sleep 1
        if curl -s --max-time 1 "$PROXY_URL/" &>/dev/null; then
            echo "âœ… å¤‰æ›ãƒ—ãƒ­ã‚­ã‚·èµ·å‹•å®Œäº† (PID: $pid, port: $PROXY_PORT)"
            return 0
        fi
    done

    echo "âŒ ã‚¨ãƒ©ãƒ¼: å¤‰æ›ãƒ—ãƒ­ã‚­ã‚·ãŒèµ·å‹•ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    echo ""
    echo "å¯¾å‡¦æ³•:"
    echo "  python3 ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª: python3 --version"
    echo "  ãƒ­ã‚°ã‚’ç¢ºèª: cat /tmp/claude-local-proxy.log"
    return 1
}

# --- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãƒã‚§ãƒƒã‚¯ ---
check_network() {
    curl -s --max-time 3 https://api.anthropic.com/ &>/dev/null
}

# --- ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— ---
cleanup() {
    if [ -f "$PROXY_PID_FILE" ]; then
        kill "$(cat "$PROXY_PID_FILE")" 2>/dev/null || true
        rm -f "$PROXY_PID_FILE"
    fi
}
trap cleanup EXIT

# --- å¼•æ•°ãƒ‘ãƒ¼ã‚¹ ---
AUTO_MODE=0
EXTRA_ARGS=()

while [[ $# -gt 0 ]]; do
    case "$1" in
        --auto)
            AUTO_MODE=1
            shift
            ;;
        --model)
            MODEL="$2"
            shift 2
            ;;
        *)
            EXTRA_ARGS+=("$1")
            shift
            ;;
    esac
done

# --- è‡ªå‹•åˆ¤å®šãƒ¢ãƒ¼ãƒ‰ ---
if [ "$AUTO_MODE" -eq 1 ]; then
    if check_network; then
        echo "ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚ã‚Š â†’ é€šå¸¸ã® Claude Code ã‚’èµ·å‹•"
        exec claude "${EXTRA_ARGS[@]}"
    else
        echo "ğŸ“¡ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãªã— â†’ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ ($MODEL)"
    fi
fi

# --- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹• ---
ensure_ollama || exit 1

# ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ç¢ºèª
if ! curl -s "$OLLAMA_HOST/api/tags" | grep -q "$MODEL"; then
    echo "âŒ ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ« $MODEL ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
    echo ""
    echo "å¯¾å‡¦æ³•:"
    echo "  ollama pull $MODEL"
    echo ""
    echo "åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:"
    curl -s "$OLLAMA_HOST/api/tags" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    for m in data.get('models', []):
        print(f\"  - {m['name']}\")
except: pass
" 2>/dev/null || echo "  (ä¸€è¦§å–å¾—å¤±æ•—)"
    exit 1
fi

# å¤‰æ›ãƒ—ãƒ­ã‚­ã‚·èµ·å‹•
ensure_proxy || exit 1

echo ""
echo "============================================"
echo " ğŸ¤– Claude Code (ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰)"
echo " Model: $MODEL"
echo " Proxy: $PROXY_URL â†’ $OLLAMA_HOST"
echo " Permissions: ãƒ„ãƒ¼ãƒ«è‡ªå‹•è¨±å¯ (ãƒ­ãƒ¼ã‚«ãƒ«å°‚ç”¨)"
echo "============================================"
echo ""

ANTHROPIC_BASE_URL="$PROXY_URL" \
ANTHROPIC_API_KEY="local" \
exec claude --model "$MODEL" --dangerously-skip-permissions "${EXTRA_ARGS[@]}"
